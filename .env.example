# ============================================================================
# MADACE-Method v2.0 - Environment Configuration
# ============================================================================
# Copy this file to .env and fill in your actual values
# DO NOT commit .env to git (it's in .gitignore)
#
# Quick Start:
#   1. cp .env.example .env
#   2. Edit .env with your API keys
#   3. Choose your LLM provider (gemini/claude/openai/local)
#   4. Start development: npm run dev
#
# Documentation: docs/LLM-SELECTION.md
# ============================================================================

# ============================================================================
# LLM CONFIGURATION - Planning & Architecture Phase
# ============================================================================
# Choose ONE of the following LLM providers for planning/architecture:
# - gemini  (Recommended - Free tier available, 60 req/min)
# - claude  (Best reasoning, paid API)
# - openai  (Popular choice, paid API)
# - local   (Privacy-focused, requires Ollama)

PLANNING_LLM=gemini

# ----------------------------------------------------------------------------
# Google Gemini Configuration
# ----------------------------------------------------------------------------
# Get your API key: https://aistudio.google.com/app/apikey
# Free tier: 60 requests/minute, 1500 requests/day
# Models: gemini-2.0-flash-exp, gemini-1.5-pro, gemini-1.5-flash

GEMINI_API_KEY=your-gemini-api-key-here
GEMINI_MODEL=gemini-2.0-flash-exp

# ----------------------------------------------------------------------------
# Anthropic Claude Configuration
# ----------------------------------------------------------------------------
# Get your API key: https://console.anthropic.com/account/keys
# Paid API - Best for complex reasoning
# Models: claude-3-5-sonnet-20241022, claude-3-opus-20240229

CLAUDE_API_KEY=your-claude-api-key-here
CLAUDE_MODEL=claude-3-5-sonnet-20241022

# ----------------------------------------------------------------------------
# OpenAI Configuration
# ----------------------------------------------------------------------------
# Get your API key: https://platform.openai.com/api-keys
# Paid API - Popular choice
# Models: gpt-4-turbo-preview, gpt-4, gpt-3.5-turbo

OPENAI_API_KEY=your-openai-api-key-here
OPENAI_MODEL=gpt-4-turbo-preview

# ----------------------------------------------------------------------------
# Local Model Configuration (Ollama)
# ----------------------------------------------------------------------------
# Requires Ollama running locally: https://ollama.ai/
# Free and private - runs on your hardware
# Models: llama2, codellama, mistral, mixtral

LOCAL_MODEL_URL=http://localhost:11434
LOCAL_MODEL_NAME=llama2

# ============================================================================
# APPLICATION CONFIGURATION
# ============================================================================

# ----------------------------------------------------------------------------
# Project Settings
# ----------------------------------------------------------------------------
PROJECT_NAME=MADACE-Method v2.0
OUTPUT_FOLDER=docs
USER_NAME=Your Name
COMMUNICATION_LANGUAGE=en

# ----------------------------------------------------------------------------
# Data Paths (for Docker deployment)
# ----------------------------------------------------------------------------
# These paths are used when running in Docker containers
# For local development, relative paths are used automatically

MADACE_DATA_DIR=/app/data
MADACE_CONFIG_FILE=/app/data/config/config.yaml
MADACE_ENV_FILE=/app/data/config/.env

# ----------------------------------------------------------------------------
# MADACE Directories (relative paths for local dev)
# ----------------------------------------------------------------------------
AGENTS_PATH=madace/mam/agents
WORKFLOWS_PATH=madace/mam/workflows
STATUS_FILE=docs/mam-workflow-status.md

# ============================================================================
# RUNTIME CONFIGURATION
# ============================================================================

# ----------------------------------------------------------------------------
# Next.js Configuration
# ----------------------------------------------------------------------------
# Development: http://localhost:3000
# Production: Set to your domain

NODE_ENV=development
NEXT_PUBLIC_APP_URL=http://localhost:3000

# ----------------------------------------------------------------------------
# Development Server
# ----------------------------------------------------------------------------
PORT=3000
HOSTNAME=0.0.0.0

# ----------------------------------------------------------------------------
# CLI Integration
# ----------------------------------------------------------------------------
# Enable Claude CLI integration
CLAUDE_CLI_ENABLED=true

# Enable Gemini CLI integration
GEMINI_CLI_ENABLED=true

# ----------------------------------------------------------------------------
# WebSocket Configuration (for CLI/Web UI sync)
# ----------------------------------------------------------------------------
# Real-time synchronization between Web UI and CLI
WEBSOCKET_ENABLED=true
WEBSOCKET_PORT=3001

# ============================================================================
# OPTIONAL CONFIGURATION
# ============================================================================

# ----------------------------------------------------------------------------
# Logging
# ----------------------------------------------------------------------------
LOG_LEVEL=info
# Options: error, warn, info, debug, trace

# ----------------------------------------------------------------------------
# Module Configuration
# ----------------------------------------------------------------------------
# Enable/disable MADACE modules
MAM_ENABLED=true
MAB_ENABLED=false
CIS_ENABLED=false

# ----------------------------------------------------------------------------
# Development Tools (for Development Container)
# ----------------------------------------------------------------------------
# VSCode Server and Cursor IDE passwords
# Change these for shared/remote environments!
VSCODE_SERVER_PASSWORD=madace123
CODE_SERVER_PASSWORD=madace123

# ----------------------------------------------------------------------------
# Implementation Agent (Automatic)
# ----------------------------------------------------------------------------
# Implementation uses local Docker agent (no configuration needed)
IMPLEMENTATION_AGENT=docker
IMPLEMENTATION_MODEL=auto

# ============================================================================
# SETUP INSTRUCTIONS
# ============================================================================
#
# 1. Copy this file:
#    cp .env.example .env
#
# 2. Choose your LLM provider and add API key:
#    - Edit PLANNING_LLM (gemini/claude/openai/local)
#    - Add your API key to the corresponding {PROVIDER}_API_KEY variable
#    - Optionally customize the model name
#
# 3. (Optional) Customize project settings:
#    - PROJECT_NAME: Your project name
#    - USER_NAME: Your name for document headers
#    - OUTPUT_FOLDER: Where documents are generated
#
# 4. Start development:
#    npm run dev
#    # Or use Docker: docker-compose -f docker-compose.dev.yml up -d
#
# 5. Access the application:
#    - Web UI: http://localhost:3000
#    - VSCode Server (Docker): http://localhost:8080
#
# ============================================================================
# DOCUMENTATION & HELP
# ============================================================================
#
# LLM Selection Guide:     docs/LLM-SELECTION.md
# Architecture Reference:  ARCHITECTURE.md
# Usage Guide:             USING-MADACE.md
# Project README:          README.md
#
# Interactive LLM Setup:   ./scripts/select-llm.sh
# Test LLM Connection:     ./scripts/test-llm.sh
#
# ============================================================================
# SECURITY NOTES
# ============================================================================
#
# ⚠️  NEVER commit .env to git (it's in .gitignore)
# ✅  Only .env.example (with placeholders) is committed
# ✅  Use different API keys for development and production
# ✅  Rotate API keys regularly
# ✅  For production: Use environment variables from hosting provider
#
# ============================================================================
